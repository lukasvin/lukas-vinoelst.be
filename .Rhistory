resultaten = rbind(resultaten,cbind(
APER=aer(V1,knn(wijnScaledSp, wijnScaledSp, V1, k),FALSE),
LOOV=aer(V1,knn.cv(wijnScaledSp,V1,k),FALSE),
CV=aer(V1[validate],knn(wijnScaledSp[train,],wijnScaledSp[validate,],V1[train],k),FALSE)
))
}
head(resultaten)
plot(c(0,78),c(0,1),xlab="Number of neigbours",ylab="Error rate",type="n");
matplot(1:78,resultaten,type='l',add=TRUE)
CV
#CV wss beste (alhoewel ik denk da er in de opdracht specifiek al verwacht wordt dat we dat doen)
resultaten
lda.er = aer(wijnScaledSp$V1[validate],lda.pred.val$class)
qda.er = aer(wijnScaledSp$V1[validate],qda.pred.val$class)
max_k = 78;
resultaten = cbind(APER=NULL,LOOV=NULL,CV=NULL)
klijst = 1:max_k
for (k in klijst) {
resultaten = rbind(resultaten,cbind(
APER=aer(V1,knn(wijnScaledSp, wijnScaledSp, V1, k),FALSE),
LOOV=aer(V1,knn.cv(wijnScaledSp,V1,k),FALSE),
CV=aer(V1[validate],knn(wijnScaledSp[train,],wijnScaledSp[validate,],V1[train],k),FALSE)
))
}
head(resultaten)
plot(c(0,78),c(0,1),xlab="Number of neigbours",ylab="Error rate",type="n"); abline(h=lda.er, col = "blueviolet"); abline(h=qda.er, col="chartreuse")
matplot(1:78,resultaten,type='l',add=TRUE)
resultaten
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.er = aer(wijnScaledSp$V1[validate],lda.pred.val$class)
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,])
qda.er = aer(wijnScaledSp$V1[validate],qda.pred.val$class)
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.er = aer(wijnScaledSp$V1[validate],lda.pred.val$class)
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,])
qda.er = aer(wijnScaledSp$V1[validate],qda.pred.val$class)
max_k = 78;
resultaten = cbind(APER=NULL,LOOV=NULL,CV=NULL)
klijst = 1:max_k
for (k in klijst) {
resultaten = rbind(resultaten,cbind(
APER=aer(V1,knn(wijnScaledSp, wijnScaledSp, V1, k),FALSE),
LOOV=aer(V1,knn.cv(wijnScaledSp,V1,k),FALSE),
CV=aer(V1[validate],knn(wijnScaledSp[train,],wijnScaledSp[validate,],V1[train],k),FALSE)
))
}
head(resultaten)
plot(c(0,78),c(0,1),xlab="Number of neigbours",ylab="Error rate",type="n"); abline(h=lda.er, col = "blueviolet"); abline(h=qda.er, col="chartreuse")
matplot(1:78,resultaten,type='l',add=TRUE)
lda.ervec = c(1:50)
qda.ervec = c(1:50)
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.ervec[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class)
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,])
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class)
}
#gemiddelde error-rate van 50 opdelingen
lda.er = mean(lda.ervec)
qda.er = mean(qda.ervec)
lda.ervec = c(1:50)
qda.ervec = c(1:50)
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.ervec[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE)
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,])
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE)
}
#gemiddelde error-rate van 50 opdelingen
lda.er = mean(lda.ervec)
qda.er = mean(qda.ervec)
lda.ervec = c(1:50)
qda.ervec = c(1:50)
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.ervec[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE)
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,])
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE)
}
#gemiddelde error-rate van 50 opdelingen
lda.er = mean(lda.ervec)
qda.er = mean(qda.ervec)
lda.ervec = c(1:50)
qda.ervec = c(1:50)
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.ervec[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE)
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,])
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE)
}
#gemiddelde error-rate van 50 opdelingen
lda.er = mean(lda.ervec)
qda.er = mean(qda.ervec)
lda.ervec = c(1:50)
qda.ervec = c(1:50)
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.ervec[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE)
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,])
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE)
}
#gemiddelde error-rate van 50 opdelingen
lda.er = mean(lda.ervec)
qda.er = mean(qda.ervec)
lda.ervec = c(1:50)
qda.ervec = c(1:50)
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.ervec[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE)
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,])
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE)
}
#gemiddelde error-rate van 50 opdelingen
lda.er = mean(lda.ervec)
qda.er = mean(qda.ervec)
max_k = 78;
resultaten = cbind(APER=NULL,LOOV=NULL,CV=NULL);
klijst = 1:max_k;
for (k in klijst) {
resultaten = rbind(resultaten,cbind(
APER=aer(V1,knn(wijnScaledSp, wijnScaledSp, V1, k),FALSE),
LOOV=aer(V1,knn.cv(wijnScaledSp,V1,k),FALSE),
CV=aer(V1[validate],knn(wijnScaledSp[train,],wijnScaledSp[validate,],V1[train],k),FALSE)
))
}
head(resultaten)
plot(c(0,78),c(0,1),xlab="Number of neigbours",ylab="Error rate",type="n"); abline(h=lda.er, col = "blueviolet"); abline(h=qda.er, col="chartreuse")
matplot(1:78,resultaten,type='l',add=TRUE)
resultaten
#Loov geeft beste resultaten maar ik denk dat er in de opdracht specifiek verwacht wordt dat we CV doen met de train, en validate/test sets
#voor CV: 3, 5 en 16 neighbours geeft abs minimum
best_k = wich.min(resultaten[,3])
best_k = which.min(resultaten[,3])
best_k
resultaten[,3]
lda.ervec.val = c(1:50);
lda.ervec.test = c(1:50);
qda.ervec = c(1:50);
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.pred.test <- predict(wijn.lda, wijnScaledSp[test,]);
lda.ervec.val[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE);
lda.ervec.test[i] = aer(wijnScaledSp$V1[test],lda.pred.test$class,conf=FALSE);
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,]);
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE);
}
#gemiddelde error-rates van 50 opdelingen
lda.er.val = mean(lda.ervec.val);lda.er.val
lda.er.test = mean(lda.ervec.test);lda.er.test
qda.er = mean(qda.ervec);qda.er
##----------------------------------------------------------------------
#k-nearest-neighboursmethode
#zoek k met kleinste error rate
max_k = 78;
resultaten = cbind(APER=NULL,LOOV=NULL,CV=NULL);
klijst = 1:max_k;
for (k in klijst) {
resultaten = rbind(resultaten,cbind(
APER=aer(V1,knn(wijnScaledSp, wijnScaledSp, V1, k),FALSE),
LOOV=aer(V1,knn.cv(wijnScaledSp,V1,k),FALSE),
CV=aer(V1[validate],knn(wijnScaledSp[train,],wijnScaledSp[validate,],V1[train],k),FALSE)
))
}
plot(c(0,78),c(0,1),xlab="Number of neigbours",ylab="Error rate",type="n"); abline(h=lda.er, col = "blueviolet"); abline(h=qda.er, col="chartreuse")
matplot(1:78,resultaten,type='l',add=TRUE)
best_k = which.min(resultaten[,3])
resultaten
lda.er.test #al berekend in vorige sectie
CV=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE); CV
lda.ervec.val = c(1:50);
lda.ervec.test = c(1:50);
qda.ervec = c(1:50);
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.pred.test <- predict(wijn.lda, wijnScaledSp[test,]);
lda.ervec.val[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE);
lda.ervec.test[i] = aer(wijnScaledSp$V1[test],lda.pred.test$class,conf=FALSE);
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,]);
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE);
}
library(MASS)
library(class)
wijn <- read.csv("wijn.csv", header=FALSE, sep = ",")
attach(wijn)
summary(wijn)
aer = function(y1,y2,conf=TRUE) {
confusion = table(y1,y2)
if (conf) {print(confusion)}
observaties = sum(confusion)
verkeerd = observaties-sum(diag(confusion))
verkeerd/observaties
}
lda.ervec.val = c(1:50);
lda.ervec.test = c(1:50);
qda.ervec = c(1:50);
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.pred.test <- predict(wijn.lda, wijnScaledSp[test,]);
lda.ervec.val[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE);
lda.ervec.test[i] = aer(wijnScaledSp$V1[test],lda.pred.test$class,conf=FALSE);
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,]);
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE);
}
#gemiddelde error-rates van 50 opdelingen
lda.er.val = mean(lda.ervec.val);lda.er.val
lda.er.test = mean(lda.ervec.test);lda.er.test
qda.er = mean(qda.ervec);qda.er
max_k = 78;
resultaten = cbind(CV=NULL);
klijst = 1:max_k;
for (k in klijst) {
resultaten = rbind(resultaten,cbind(
CV=aer(V1[validate],knn(wijnScaledSp[train,],wijnScaledSp[validate,],V1[train],k),FALSE)
))
}
head(resultaten)
plot(c(0,78),c(0,1),xlab="Number of neigbours",ylab="Error rate",type="n"); abline(h=lda.er, col = "blueviolet"); abline(h=qda.er, col="chartreuse")
matplot(1:78,resultaten,type='l',add=TRUE)
best_k = which.min(resultaten[,3])
resultaten
lda.er.test #al berekend in vorige sectie
CV=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE); CV
lda.er.test #al berekend in vorige sectie
CV=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE); CV
lda.er.test #al berekend in vorige sectie
CV=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE); CV
lda.er.test #al berekend in vorige sectie
CV.test.ervec = c(1:50)
for (j in 1:50) {
CV.test.ervec[j]=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE);
}
CV.er.test = mean(CV.ervec); CV.er.test
lda.er.test #al berekend in vorige sectie
CV.test.ervec = c(1:50)
for (j in 1:50) {
CV.test.ervec[j]=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE);
}
CV.er.test = mean(CV.test.ervec); CV.er.test
lda.er.test #al berekend in vorige sectie
CV.test.ervec = c(1:50)
for (j in 1:50) {
CV.test.ervec[j]=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE);
}
#gemiddelde error rate van 50
CV.er.test = mean(CV.test.ervec); CV.er.test
lda.er.test #al berekend in vorige sectie
CV.test.ervec = c(1:50)
for (j in 1:50) {
CV.test.ervec[j]=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE);
}
#gemiddelde error rate van 50
CV.er.test = mean(CV.test.ervec); CV.er.test
lda.er.test #al berekend in vorige sectie
CV.test.ervec = c(1:50)
for (j in 1:50) {
CV.test.ervec[j]=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE);
}
#gemiddelde error rate van 50
CV.er.test = mean(CV.test.ervec); CV.er.test
lda.er.test #al berekend in vorige sectie
CV.test.ervec = c(1:50)
for (j in 1:50) {
CV.test.ervec[j]=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE);
}
#gemiddelde error rate van 50
CV.er.test = mean(CV.test.ervec); CV.er.test
lda.er.test #al berekend in vorige sectie
CV.test.ervec = c(1:50)
for (j in 1:50) {
CV.test.ervec[j]=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE);
}
#gemiddelde error rate van 50
CV.er.test = mean(CV.test.ervec); CV.er.test
lda.er.test #al berekend in vorige sectie
CV.test.ervec = c(1:50)
for (j in 1:50) {
CV.test.ervec[j]=aer(V1[test],knn(wijnScaledSp[train,],wijnScaledSp[test,],V1[train],best_k),FALSE);
}
#gemiddelde error rate van 50
CV.er.test = mean(CV.test.ervec); CV.er.test
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.pred.test <- predict(wijn.lda, wijnScaledSp[test,]);
lda.ervec.val[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE);
lda.ervec.test[i] = aer(wijnScaledSp$V1[test],lda.pred.test$class,conf=FALSE);
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,]);
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE);
}
#gemiddelde error-rates van 50 opdelingen
lda.er.val = mean(lda.ervec.val);lda.er.val
lda.er.test = mean(lda.ervec.test);lda.er.test
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.pred.test <- predict(wijn.lda, wijnScaledSp[test,]);
lda.ervec.val[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE);
lda.ervec.test[i] = aer(wijnScaledSp$V1[test],lda.pred.test$class,conf=FALSE);
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,]);
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE);
}
#gemiddelde error-rates van 50 opdelingen
lda.er.val = mean(lda.ervec.val);lda.er.val
lda.er.test = mean(lda.ervec.test);lda.er.test
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.pred.test <- predict(wijn.lda, wijnScaledSp[test,]);
lda.ervec.val[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE);
lda.ervec.test[i] = aer(wijnScaledSp$V1[test],lda.pred.test$class,conf=FALSE);
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,]);
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE);
}
#gemiddelde error-rates van 50 opdelingen
lda.er.val = mean(lda.ervec.val);lda.er.val
lda.er.test = mean(lda.ervec.test);lda.er.test
for (i in 1:50) {
indices = 1:178;
test = sample(178,50);
validate_train = indices[-test];
validate = sample(validate_train,50);
train = validate_train[-which(validate_train %in% validate)];
##-----------------------------------------------------------------------
#determinantmethode
#lineair
wijn.lda <- lda(V1 ~.,wijnScaledSp ,subset = train);
lda.pred.val <- predict(wijn.lda, wijnScaledSp[validate,]);
lda.pred.test <- predict(wijn.lda, wijnScaledSp[test,]);
lda.ervec.val[i] = aer(wijnScaledSp$V1[validate],lda.pred.val$class,conf=FALSE);
lda.ervec.test[i] = aer(wijnScaledSp$V1[test],lda.pred.test$class,conf=FALSE);
#quadratisch
wijn.qda <- qda(V1 ~.,wijnScaledSp ,subset = train);
qda.pred.val <- predict(wijn.qda, wijnScaledSp[validate,]);
qda.ervec[i] = aer(wijnScaledSp$V1[validate],qda.pred.val$class,conf=FALSE);
}
#gemiddelde error-rates van 50 opdelingen
lda.er.val = mean(lda.ervec.val);lda.er.val
lda.er.test = mean(lda.ervec.test);lda.er.test
plot(c(0,78),c(0,1),main="Error rate in function of neighbours",xlab="Number of neigbours",ylab="Error rate",type="n"); abline(h=lda.er, col = "blueviolet"); abline(h=qda.er, col="chartreuse")
matplot(1:78,resultaten,type='l',add=TRUE)
legend(x, y=NULL, legend=c('knn','lda','qda'), col=c("black","blueviolet","chartreuse"))
plot(c(0,78),c(0,1),main="Error rate in function of neighbours",xlab="Number of neigbours",ylab="Error rate",type="n"); abline(h=lda.er, col = "blueviolet"); abline(h=qda.er, col="chartreuse")
matplot(1:78,resultaten,type='l',add=TRUE)
legend(x=0, y=0.8, legend=c('knn','lda','qda'), col=c("black","blueviolet","chartreuse"))
plot(c(0,78),c(0,1),main="Error rate in function of neighbours",xlab="Number of neigbours",ylab="Error rate",type="n"); abline(h=lda.er, col = "blueviolet"); abline(h=qda.er, col="chartreuse")
matplot(1:78,resultaten,type='l',add=TRUE)
legend(x=0, y=0.8, legend=c('knn','lda','qda'), fill=c("black","blueviolet","chartreuse"))
